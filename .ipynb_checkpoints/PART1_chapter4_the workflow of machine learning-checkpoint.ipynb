{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter4 : Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 The universal workflow of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Defining the problem and assembling a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you must define the problem at hand :\n",
    "  + What will your input data be? What are you trying to predict?\n",
    "    + Data availability is usually the limiting factor at this stage\n",
    "  + What type of problem are you facing?\n",
    "    + Identifying the problem type will guide your choice of model architecture, loss function, and so on.\n",
    "    \n",
    "You can't move to the next stage until you know what your inputs and outputs are, and what data you'll use.\n",
    "\n",
    "**Keep in mind that machine learning can only be used to memorize patterns that are present in your training data.** This means using machine learning training on past data to predict the future is making the assumption that the future will behave like the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Choosing a measure of success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your metric for success will guide the choice of a loss function: what your model will optimize.\n",
    "\n",
    "data type                        | metric\n",
    "---------------------------------|-----------------------\n",
    "balanced-classification problems | accuracy, ROC AUC\n",
    "class-imbalanced problems        | precision, recall\n",
    "ranking problems                 | mean average precison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Deciding on an evaluation protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you must establish how you'll measure your current progress. We've reviewed three common evaluation protocols:\n",
    "  + *Maintaining a hold-out validation set*--The way to go when you have plenty of data\n",
    "  + *Doing K-fold cross-validation*--The right choice when you have too few samples for hold-out validation to be reliable\n",
    "  + *Doing iterated K-fold validation*--For performing highly accurate model evaluation when little data is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 Preparing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should format your data in a way that can be fed into a machine-learning model--here, we'll assume a deep neural network:\n",
    "  + Your data should be formatted as tensors\n",
    "  + The values taken by these tensors should usually be scaled to small values\n",
    "    - if different features take values in different ranges (heterogeneous data), then the data should be normalized.\n",
    "  + You may want to do some feature engineering, especially for small-data problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5 Developing a model that does better than a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal at this stage is to achieve ***statistical power***.\n",
    "\n",
    "Note that it's not always possible to achieve statistical power. If you can't beat a random baseline after trying multiple reasonable architectures, it may be that the answer to the question you're asking isn't present in the input data.\n",
    "\n",
    "Assuming that things go well, you need to make three key choices to build your first working model:\n",
    "  + Last-layer activation\n",
    "  + Loss function\n",
    "  + Optimization configuration\n",
    "  \n",
    "Choosing the right last-layer activation and loss function for your model\n",
    "\n",
    "Problem type                           |Last-layer activation|Loss function\n",
    "---------------------------------------|---------------------|-------------\n",
    "Binary classification                  |sigmoid              |binary_crossentropy\n",
    "Multiclass, single-label classification|softmax              |categorical_crossentropy\n",
    "Multiclass, multi-label classification |sigmoid              |binary_crossentropy\n",
    "Regression to arbitrary values         |None                 |mse\n",
    "Regression to values between 0 to 1    |sigmoid              |mse, binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.6 Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've obtained a model that has statistical power, the question becomes, is your model sufficiently powerful?\n",
    "\n",
    "Remember that the universal tension in machine learning is between **optimization** and **generalization**; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity.\n",
    "\n",
    "To figure out how big a model you'll need, you must develop a model that overfits. This is fairly easy:\n",
    "  1. Add layers.\n",
    "  2. Make the layers bigger.\n",
    "  3. Train for more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.7 Regularizing your model and tuning your hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will take the most time: you'll repeatly modify your model, train it, evaluate on your validation data, modify it again, and repeat, until the model is as good as it can get. These are some things you should try:\n",
    "  + Add dropout.\n",
    "  + Try different architectures: add or remove layers.\n",
    "  + Add L1 and/or L2 regularization.\n",
    "  + Try different hyperparameters to find the optimal configuration.\n",
    "  + Optionally, iterate on feature engineering: add new features, or remove features that don't seem to be informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be mindful of the following: every time you use feedback from your validation process to tune your model, you leak information about the validation process into the model.Repeated just a few times, this is innocuous; but done systematically over many iterations, it will eventually cause your model to overfit to the validation process.\n",
    "\n",
    "Once you've developed a satisfactory model configuration, evaluate it one last time on the test set. If it turns out that performance on the test set is significantly worse than the performance measured on the validation data, it can mean two things:\n",
    "  + your validation procedure wasn't reliable after all\n",
    "  + you began overfitting to the validation data while tuning the parameters of the model\n",
    "\n",
    "In this case, you may want to switch to a more reliable evaluation protocol (such as iterated K-fold validation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
