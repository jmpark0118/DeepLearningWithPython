{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-nnQH_CTiqg"
   },
   "source": [
    "# Chapter7 : Advanced deep-learning best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkdpXn4xTiqh"
   },
   "source": [
    "This chapter explores a number of powerful tools that will bring you closer to being able to develop state-of-the-art models on difficult problems. Using the Keras functional API, you can build graph-like models, share a layer across different inputs, and use Keras models just like Python functions. We'll also discuss several other best practices including batch normalization, residual connections, hyperparameter optimization, and model ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB3j8jpYTiqh"
   },
   "source": [
    "## 7.1 Going beyond the Sequential model: the Keras functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQcn8kcPTiqi"
   },
   "source": [
    "Until now, all neural networks introduced in this book have been implemented using the `Sequential` model. The `Sequential` model makes the assumption that the network has exactly one input and exactly one output, and that it consists of a linear stack of layers. However, this set of assumptions is too inflexible in a number of cases.\n",
    "\n",
    "Some tasks, for instance, require *multimodal* inputs: they merge data coming from different input sources, processing each type of data using different kinds of neural layers. A naive approach would be to train separate models and then do a weighted average of their predictions. But this may be suboptimal, because the information extracted by the models my be redundant. A better way is to *jointly* learn a more accurate model of the data by using a model that can see all available input modalities simultaneously: a model with three input branches.\n",
    "<img src=\"image/fig72.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qz8zTd0Tiqi"
   },
   "source": [
    "Similarly, some tasks need to predict multiple target attributes of input data. Of course, you could train two separte models, but you could build a better model by learning to jointly predict targets at the same time.\n",
    "<img src='image/fig73.png' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu0g7Or4Tiqj"
   },
   "source": [
    "Additionally, many recently developed neural architectures require nonlinear network topology: networks structured as directed acyclic graphs. The Inception family of networks, for instance, relies on *Inception modules*, where the input is processed by several parallel convolutional branches whose outputs are then merged back into a single tensor.\n",
    "<img src='image/fig74.png' width='450'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mGR5RoUTiqk"
   },
   "source": [
    "There's also the recent trend of adding *residual connections* to a model. A residual connection consists of reinjecting previous representations into the downstream flow of data by adding a past output tensor to a later output tensor, which helps prevent information loss along the data-processing flow.\n",
    "<img src='image/fig75.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFihW2J1Tiqk"
   },
   "source": [
    "### 7.1.1 Introduction to the functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RP5Am_pETiqk"
   },
   "source": [
    "In the functional API, you directly manipulate tensors, and you use layers as *functions* that take tensors and return tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I4rE6jfGTiql",
    "outputId": "4f72df9e-2863-4f19-c28d-cccf3f4da47b"
   },
   "outputs": [],
   "source": [
    "from keras import Input, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kWRZ9k6Tiqo"
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(32,))             # a tensor\n",
    "dense = layers.Dense(32, activation='relu')   # a layer is a function\n",
    "output_tensor = dense(input_tensor)           # returns a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R9qS-HW5Tiqq"
   },
   "source": [
    "The following is a minimal example that shows side by side a simple `Sequential` model and its equivalent in the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "jmfZlSHMTiqr",
    "outputId": "b24210ea-9c42-41e2-c2f7-421a2c5ccf06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# Sequential model (which you already know about!)\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Its functional equivalent\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# the `Model` class turns an input tensor and output tensor into a model\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPbnqSPnTiqu"
   },
   "source": [
    "When it comes to compiling, training, or evaluating such an instance of `Model`, the API is the same as that of `Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "PLnULxIITiqu",
    "outputId": "59a0c01a-c831-47c8-b978-cff876a7ab38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 11.8087 - val_loss: 12.2828\n",
      "Epoch 2/10\n",
      " - 0s - loss: 12.1982 - val_loss: 13.2863\n",
      "Epoch 3/10\n",
      " - 0s - loss: 13.4401 - val_loss: 15.0153\n",
      "Epoch 4/10\n",
      " - 0s - loss: 15.3179 - val_loss: 17.1669\n",
      "Epoch 5/10\n",
      " - 0s - loss: 17.4612 - val_loss: 19.9794\n",
      "Epoch 6/10\n",
      " - 0s - loss: 20.4400 - val_loss: 23.1770\n",
      "Epoch 7/10\n",
      " - 0s - loss: 23.8272 - val_loss: 27.2266\n",
      "Epoch 8/10\n",
      " - 0s - loss: 28.0020 - val_loss: 31.9996\n",
      "Epoch 9/10\n",
      " - 0s - loss: 32.9151 - val_loss: 37.0635\n",
      "Epoch 10/10\n",
      " - 0s - loss: 38.0761 - val_loss: 43.1848\n",
      "1000/1000 [==============================] - 0s 49us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10, batch_size=128,\n",
    "          validation_split=0.2,\n",
    "          verbose=2)\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhAe_Q7lTiqx"
   },
   "source": [
    "### 7.1.2 Multi-input models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20MtnqbqTiqx"
   },
   "source": [
    "The functional API can be used to build models that have multiple inputs. Typically, such models at some point merge their different input branches using a layer that can combine several tensors: by adding them, concatenating them, and so on.\n",
    "\n",
    "Let's look at a very simple example of a multi-input model: a **question-answering model**. A typical question-answering model has two inputs: a natural-language question and a text snippet (such as a news article) providing information to be used for answering the question.\n",
    "\n",
    "<img src='image/fig76.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hac4GsYHTiqy"
   },
   "source": [
    "Following is the example of how you can build such a model with the functional API. You set up two independent branches, encoding the text input and the question input as representation vectors; then, concatenate these vectors; and finally, add a softmax classifier on top of the concatenated representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KUj8CprTiqz"
   },
   "source": [
    "#### Functional API implementation of a two-input question-answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwsgQxKiTiqz"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Any5xxQBTiq2"
   },
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# text input is a variable length sequence of integers\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# same process for the question\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# concatenates the encoded question and encoded text\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# adds a softmax classifier on top\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "OGTu8xAJTiq4",
    "outputId": "51f8ff90-64fe-4392-8ade-67d8cf8da1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           12416       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 16)           3136        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 48)           0           lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 500)          24500       concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3W7swHGhTiq6"
   },
   "source": [
    "#### Feeding data to a multi-input model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wc_YyQCMTiq6"
   },
   "source": [
    "There are two possible APIs:\n",
    "  + feed the model a list of Numpy arrays as inputs\n",
    "  + feed it a dictionary that maps input names to Numpy arrays\n",
    "    - (available only if you give names to your inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lD6znjP_Tiq7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, \n",
    "                         size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, \n",
    "                             size=(num_samples, max_length))\n",
    "answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n",
    "answers = keras.utils.to_categorical(answers, answer_vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "yk7AfQOzTiq-",
    "outputId": "7e6b5e46-b7ab-41a7-df03-be644d96ce67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 6.2146 - acc: 0.0040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 6.1969 - acc: 0.0500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 6.1461 - acc: 0.0140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 6.0548 - acc: 0.0060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.9646 - acc: 0.0050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.8797 - acc: 0.0090\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.7770 - acc: 0.0200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.6761 - acc: 0.0220\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.5874 - acc: 0.0390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.5010 - acc: 0.0450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368f02c860>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting using a list of inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "mETqm5MlTirB",
    "outputId": "ea372848-1326-41b4-a772-91ceba06955a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.4146 - acc: 0.0520\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.3446 - acc: 0.0620\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.2706 - acc: 0.0690\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.1923 - acc: 0.0760\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.1123 - acc: 0.0770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.0464 - acc: 0.0870\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.9589 - acc: 0.1090\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.9250 - acc: 0.0910\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.8306 - acc: 0.1230\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.7782 - acc: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368ed88860>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting using a dictionary of inputs (only if inputs are named)\n",
    "model.fit({'text': text, 'question': question}, answers, \n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4w3ck3FTirC"
   },
   "source": [
    "### 7.1.3 Multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcAmSoxlTirD"
   },
   "source": [
    "In the same way, you can use the functional API to build models with multiple outputs (or multiple *heads*).\n",
    "\n",
    "A simple example is a network that attempts to simultaneously predict different properties of the data, such as a network that tries to predict attributes of a single person, such as age, gender, and income level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwNRM5CvTirD"
   },
   "source": [
    "#### Functional API implementation of a three-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uz4JzZ0NTirE"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqhBoidNTirG"
   },
   "source": [
    "<img src='image/fig77.png' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "rvEm1eCmTirG",
    "outputId": "fc09924f-437d-4f12-ef07-9dc21b0da53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 128)    163968      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 128)    0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 256)    164096      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 256)    327936      conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, None, 256)    0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 256)    327936      max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 256)    327936      conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          32896       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu', padding='same')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',\n",
    "                                 name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UacxZZDNTirI"
   },
   "source": [
    "#### Compilation options of a multi-output model: multiple losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ7z5FYUTirI"
   },
   "source": [
    "In Keras, you can use either a list or a dictionary of losses in `compile` to specify different objects for different outputs; the resulting loss values are summed into a global loss, which is minimized during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbJT0GxJTirJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Au_Dl8HcTirL"
   },
   "outputs": [],
   "source": [
    "# equivalent to the above\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJd1dNNUTirO"
   },
   "source": [
    "#### Compilation options of a multi-output model: loss weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CStvQF6TirP"
   },
   "source": [
    "Note that very imbalanced loss contributions will cause the model representations to be optimized preferentially for the task with the largest individual loss, at the expense of the other tasks. To remedy this, you can **assign different levels of importance to the loss values** in their contribution to the final loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "op4SSVYHTirP"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqlHiBIqTirR"
   },
   "outputs": [],
   "source": [
    "# equivalent to the above\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxPxkbhMTirT"
   },
   "source": [
    "#### Feeding data to a multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1rjpNKyTirT"
   },
   "outputs": [],
   "source": [
    "num_samples = 1000 \n",
    "max_length = 100 \n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
    "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
    "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
    "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
    "gender_targets = np.random.randint(0, 2, size=(num_samples,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "c_Tpv_cgTirV",
    "outputId": "4c1fec8a-4a5a-40b7-cb72-e392a55ee7f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 838.1333 - age_loss: 3172.2847 - income_loss: 9.0316 - gender_loss: 2.1172\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 149.5014 - age_loss: 550.2236 - income_loss: 3.8917 - gender_loss: 0.7197\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 73.7162 - age_loss: 254.9068 - income_loss: 2.7950 - gender_loss: 0.9551\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 98.6665 - age_loss: 344.7985 - income_loss: 2.3600 - gender_loss: 1.0025\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 116.2279 - age_loss: 409.1831 - income_loss: 2.3704 - gender_loss: 1.0279\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 220us/step - loss: 74.4594 - age_loss: 257.5160 - income_loss: 2.3246 - gender_loss: 0.8696\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 137.1230 - age_loss: 516.6716 - income_loss: 2.3544 - gender_loss: 0.8955\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 230us/step - loss: 70.8131 - age_loss: 236.3586 - income_loss: 2.3349 - gender_loss: 0.9016\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 85.5353 - age_loss: 294.6146 - income_loss: 2.3055 - gender_loss: 0.8526\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 78.5477 - age_loss: 269.0636 - income_loss: 2.3416 - gender_loss: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368f02c630>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "_wUKhrh0TirX",
    "outputId": "4b79a470-91ce-4997-8756-2dcef2de96fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 88.0264 - age_loss: 306.8679 - income_loss: 2.3149 - gender_loss: 0.8552\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 218us/step - loss: 84.1633 - age_loss: 282.6600 - income_loss: 2.3473 - gender_loss: 0.9709\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 221us/step - loss: 69.5221 - age_loss: 227.0768 - income_loss: 2.3054 - gender_loss: 0.9617\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 55.4598 - age_loss: 177.5604 - income_loss: 2.2929 - gender_loss: 0.8504\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 226us/step - loss: 70.3125 - age_loss: 233.2402 - income_loss: 2.3029 - gender_loss: 0.8705\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 58.3374 - age_loss: 189.1681 - income_loss: 2.3014 - gender_loss: 0.8064\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 51.3668 - age_loss: 167.8360 - income_loss: 2.3277 - gender_loss: 0.9143\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 228us/step - loss: 63.2676 - age_loss: 206.9291 - income_loss: 2.3417 - gender_loss: 0.8781\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 42.5369 - age_loss: 132.4098 - income_loss: 2.3051 - gender_loss: 0.9218\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 59.1663 - age_loss: 200.7812 - income_loss: 2.3080 - gender_loss: 0.7565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368e7d80b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to the above\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJjgG8a_TirZ"
   },
   "source": [
    "### 7.1.4 Directed acyclic graphs of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7Y-BuDETira"
   },
   "source": [
    "With the functional API, not only can you build models with multiple inputs and multiple-outputs, but you can also implement networks with a complex internal topology. Neural networks in Keras are allowed to be arbitrary *directed acyclic graphs* of layers.\n",
    "\n",
    "To better understand how the functional API can be used to build graphs of layers, let's take a look at how you can implement both of them in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNv5HiUhTirb"
   },
   "source": [
    "#### INCEPTION MODULES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2bsIh_OTirb"
   },
   "source": [
    "The most basic form of an Inception module has three to four branches starting with a 1 x 1 convolution, followed by a 3 x 3 convolution, and ending with the concatenation of the resulting features. This setup helps the network separately learn spatial features and channel-wise features, which is more efficient than learning them jointly.\n",
    "\n",
    "<img src='image/fig78.png' width='550'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdKlcFKFTirb"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, padding='same', activation='relu', strides=2)(x)\n",
    "\n",
    "# In this branch, the striding occurs in the spatial convolution layer\n",
    "branch_b = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_b)\n",
    "\n",
    "# In this branch, the striding occurs in the average pooling layer\n",
    "branch_c = layers.AveragePooling2D(3, padding='same', strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# Concatenates the branch outputs to obtain the module output\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrpEfNI9Tird"
   },
   "outputs": [],
   "source": [
    "# Adding a classifier on top of the convnet\n",
    "output = layers.Flatten()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "predictions = layers.Dense(10, activation='softmax')(output)\n",
    "\n",
    "model = keras.models.Model(inputs=x, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Iwb_olYTirf"
   },
   "source": [
    "##### Train the Inception model using the Dataset API and the MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZVDGf5ATirf"
   },
   "source": [
    "+ code source from [`ClaudeCoulombe` GitHub](https://github.com/ClaudeCoulombe/deep-learning-with-python-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeuBhJeiTirg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Clean up the TF session.\n",
    "K.clear_session()\n",
    "\n",
    "if K.backend() != 'tensorflow':\n",
    "    raise RuntimeError('This example can only run with the TensorFlow backend,'\n",
    "                       ' because it requires the Dataset API, which is not'\n",
    "                       ' supported on other platforms.')\n",
    "\n",
    "batch_size = 128\n",
    "buffer_size = 10000\n",
    "steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469\n",
    "epochs = 5\n",
    "num_classes = 10\n",
    "\n",
    "def cnn_layers(x):\n",
    "    \n",
    "    # This example assumes the existence of a 4D input tensor x:\n",
    "    # This returns a typical image tensor like those of MNIST dataset \n",
    "    print(\"x.shape:\",x.shape)\n",
    "\n",
    "    # Every branch has the same stride value (2), which is necessary to \n",
    "    # keep all branch outputs the same size so you can concatenate them\n",
    "    branch_a = layers.Conv2D(128, 1, padding='same', activation='relu', strides=2)(x)\n",
    "\n",
    "    # In this branch, the striding occurs in the spatial convolution layer.\n",
    "    branch_b = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
    "    branch_b = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_b)\n",
    "\n",
    "    # In this branch, the striding occurs in the average pooling layer.\n",
    "    branch_c = layers.AveragePooling2D(3,  padding='same', strides=2)(x)\n",
    "    branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
    "\n",
    "    branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x) \n",
    "    branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
    "    branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
    "\n",
    "    # Concatenates the branch outputs to obtain the module output\n",
    "    output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
    "\n",
    "    # Adding a classifier on top of the convnet\n",
    "    output = layers.Flatten()(output)\n",
    "    output = layers.Dense(512, activation='relu')(output)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(output)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gEJeXodgdTAq",
    "outputId": "0fb1066d-f3a3-41d0-e5c3-017e0d2210d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (128, 28, 28, 1)\n",
      "targets.shape: (128, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "y_train = tf.one_hot(y_train, num_classes)\n",
    "\n",
    "# Create the dataset and its associated one-shot iterator.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "# Model creation using tensors from the get_next() graph node.\n",
    "inputs, targets = iterator.get_next()\n",
    "\n",
    "print(\"inputs.shape:\",inputs.shape)\n",
    "print(\"targets.shape:\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fWuYPYwMdVyX",
    "outputId": "4cf0c8dc-fdad-4965-8d12-924e3f92c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (128, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "model_input = layers.Input(tensor=inputs)\n",
    "model_output = cnn_layers(model_input)\n",
    "\n",
    "model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              target_tensors=[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "id": "L6hk_25BTirh",
    "outputId": "961c195a-5e0b-47ee-fb89-b2c3b428a4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (128, 28, 28, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (128, 28, 28, 128)   256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (128, 28, 28, 128)   256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (128, 14, 14, 1)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (128, 28, 28, 128)   147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (128, 14, 14, 128)   256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (128, 14, 14, 128)   147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (128, 14, 14, 128)   1280        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (128, 14, 14, 128)   147584      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (128, 14, 14, 512)   0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (128, 100352)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (128, 512)           51380736    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (128, 10)            5130        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,830,666\n",
      "Trainable params: 51,830,666\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Sc4UbF1jTirj",
    "outputId": "4bf3fa99-fc92-44f8-c468-66c4a11821cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.4668 - accuracy: 0.9868\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.5747 - accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.5612 - accuracy: 0.9933\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.8477 - accuracy: 0.9940\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 5.1630e-11 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f368e187c50>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(epochs=epochs,\n",
    "          steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYfYKBwYTirl"
   },
   "source": [
    "#### RESIDUAL CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBbtYdORTirm"
   },
   "source": [
    "*Residual connections* are a common graph-like network component found n many post-2015 network architectures, including Xception. They tackle two common problems that plague any large-scale deep-learning model: **vanishing gradients** and **representational bottlenecks**. In general, adding residual connections to any model that has more than 10 layers is likely to be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChkHd4XRTirm"
   },
   "source": [
    "##### Implementing a residual connection in Keras when the feature-map sizes are the same, using identity residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "SY1XT9_vTirm",
    "outputId": "29bf439c-7fed-460c-961a-615b21bc42b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images (InputLayer)             (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 128)  1280        images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 128)  147584      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          51380736    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           5130        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,682,314\n",
      "Trainable params: 51,682,314\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers \n",
    "from keras.layers import Input\n",
    "\n",
    "# This example assumes the existence of a 4D input tensor x:\n",
    "# This returns a typical image tensor like those of MNIST dataset \n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "\n",
    "# Applies a transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "# Adds the original x back to the output features\n",
    "output = layers.add([y, x])\n",
    "\n",
    "# Adding a classifier on top of the convnet\n",
    "output = layers.Flatten()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "predictions = layers.Dense(10, activation='softmax')(output)\n",
    "\n",
    "model = keras.models.Model(inputs=x, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdMZf8w4Tiro"
   },
   "source": [
    "##### Implementing a residual connection when the feature-map sizes differ, using a linear residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "xIhkb6cxTirp",
    "outputId": "010081a6-0afe-464c-87ec-209b6b1c9dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (None, 28, 28, 1)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images (InputLayer)             (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  1280        images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 128)  256         images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 128)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 25088)        0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          12845568    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           5130        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,999,818\n",
      "Trainable params: 12,999,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers \n",
    "from keras.layers import Input\n",
    "\n",
    "# This example assumes the existence of a 4D input tensor x:\n",
    "# This returns a typical image tensor like those of MNIST dataset \n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "print(\"x.shape:\",x.shape)\n",
    "\n",
    "# Applies a transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# Uses a 1  1 convolution to linearly downsample the original x tensor to the same shape as y\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "# Adds the residual tensor back to the output features\n",
    "output = layers.add([y, residual])\n",
    "\n",
    "# Adding a classifier on top of the convnet\n",
    "output = layers.Flatten()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "predictions = layers.Dense(10, activation='softmax')(output)\n",
    "\n",
    "model = keras.models.Model(inputs=x, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVNDa9KSTirr"
   },
   "source": [
    "### 7.1.5 Layer weight sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3mhvn5eTirr"
   },
   "source": [
    "One more important feature of the functional API is the ability to reuse a layer instance several times. This allows you to build models that have shared branches--several branches that all share the same knowledge and perform the same operations. That is, they share the same representations and learn these representations simultaneously for different sets of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "MpGpXHRITirr",
    "outputId": "a1e181c6-19ec-4257-d1db-ff98dd332486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, None, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, None, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           20608       input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64)           0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,673\n",
      "Trainable params: 20,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# Instantiates a single LSTM layer, once\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# Builiding the left branch of the model: \n",
    "# inputs are variable-length sequences of vectors of size 128\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# Building the right branch of the model:\n",
    "# when you call an existing layer instance, you resue its weights\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# Builds the classifier on top\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Instantiating and training the model:\n",
    "# when you train such a model, the weights of the LSTM layer are updated based on both inputs\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "eqtUcSwUnt_X",
    "outputId": "c4ccbe6a-4717-469f-b50d-10155e54d61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.7236 - acc: 0.4200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3571cfe2b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 100\n",
    "num_symbols = 2\n",
    "\n",
    "left_data = np.random.randint(0, num_symbols, size=(num_samples,1,128))\n",
    "right_data = np.random.randint(0, num_symbols, size=(num_samples,1,128))\n",
    "\n",
    "matching_list = [np.random.randint(0, num_symbols) for _ in range(num_samples)]\n",
    "targets = np.array(matching_list)\n",
    "\n",
    "# We must compile a model before training/testing.\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "# Training the model: when you train such a model,\n",
    "# the weights of the LSTM layer are updated based on both inputs.\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4645gTaoVFP"
   },
   "source": [
    "### 7.1.6 Models as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kp6WU5_cqQSr"
   },
   "source": [
    "One simple practical example of what you can build by reusing a model instance is a vision model that uses a dual camera as its input: two parallel cameras, a few centimeters apart. Such low-level processing can be shared across the two inputs: that is, done via layers that use the same weights and thus share the same representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "efJ_Gv_KoOIN",
    "outputId": "dd033f75-8a9e-47a8-dee6-424469ada665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                multiple             20861480    input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 4096)   0           xception[1][0]                   \n",
      "                                                                 xception[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8, 8, 10)     40970       concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,902,450\n",
      "Trainable params: 20,847,922\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications \n",
    "from keras import Input\n",
    "\n",
    "nbr_classes = 10\n",
    "\n",
    "# The base image-processing model is the Xception network (convolutional base only).\n",
    "xception_base = applications.Xception(weights=None,include_top=False)\n",
    "\n",
    "# The inputs are 250  250 RGB images.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "# right_input = xception_base(right_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
    "\n",
    "predictions = layers.Dense(nbr_classes, activation='softmax')(merged_features)\n",
    "\n",
    "# Instantiating the model\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PART2_7.1_Going beyond the Sequential model_the Keras functional API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
